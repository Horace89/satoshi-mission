{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import helper_functions\n",
    "import textract\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Polishing Data Cleaning Pipeline\n",
    "Test before implementing in `helper_function.py`.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../raw-data/suspectA/suspectA-1.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = textract.process(filename, method='pdftotext', layout=True,\n",
    "                           encoding='ascii')                            # output encoding; input encoding is inferred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---simple data cleaning to remove artifacts/equations/text from figures/flowcharts---\n",
    "\n",
    "# line break characters (string.whitespace = '\\t', '\\n', '\\x0b', '\\x0c', '\\r', ' ')\n",
    "# \\x0c = a form feed; it forces a printer to move to the next sheet of paper.\n",
    "breaks = tuple(ch for ch in tuple(string.whitespace)[1:-1] if doc.count(ch) > 0)\n",
    "\n",
    "# remove artifact from justified text alignment and change four spaces to '\\t' (tab)\n",
    "doc = re.sub('    (?=\\w)', '\\t', doc.replace('\\n         ', '\\n'))\n",
    "\n",
    "# drop references if exist\n",
    "i = doc.find('References') * doc.find('Bibliography')  # each returns -1 if not found\n",
    "if i < 0:\n",
    "    doc = doc[:-i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split on line break characters\n",
    "sentences = re.split('|'.join(breaks), doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences2 = [s.strip(' ') for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove leading/trailing ' ' (note: can't leave strip() empty otherwise \\t is stripped as well!)\n",
    "# remove page number\n",
    "# drop empty sentences and sentences with too many white characters in it (most likely text from flowcharts)\n",
    "# drop lines where there are more digits than alphabets -- most likely an equation\n",
    "table = string.maketrans('', '')\n",
    "sentences3 = [s.strip(' ') for s in sentences if s and \\\n",
    "                                     not s.isdigit() and \\\n",
    "                                     0 < s.count(' ')/len(s) < 0.2 and \\\n",
    "                                     len(s.translate(table, string.digits + string.punctuation))/len(s) > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences4 = helper_functions.strip_misc_periods(sentences3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2 = ' '.join(sentences4) \n",
    "doc2 = re.sub('\\'ll', ' will', doc2)\n",
    "doc2 = re.sub('\\'ve', ' have' , doc2)\n",
    "doc2 = re.sub('n\\'t', ' not' , doc2)\n",
    "doc2 = re.sub('\\w+[a-z]([A-Z]|\\_\\w)\\w+', '', doc2)\n",
    "# doc2 = re.sub(r'[^\\x00-\\x7F]+',' ', doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = np.array([word for word in \\\n",
    "                 re.split(r'[^\\x00-\\x7F]|[' + string.whitespace + string.punctuation + string.digits + ']', doc2.lower()) \\\n",
    "                 if word \\\n",
    "                    and (len(word) > 1 or word in {'a', 'i', 'A', 'I'}) \\\n",
    "                    and word not in {'satoshi', 'nakamoto',\n",
    "                                     'suspectA-firstname', 'suspectA-lastname',\n",
    "                                     'suspectB-firstname', 'suspectB-lastname',\n",
    "                                     'suspectC-firstname', 'suspectC-lastname'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.Dict('en_US')\n",
    "d2 = enchant.Dict('en_GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isUS = np.array([d.check(word) or d.check(word.capitalize()) or d.check(word.upper()) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isGB = np.array([d2.check(word) or d2.check(word.capitalize()) or d2.check(word.upper()) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_en = words[~isUS&~isGB][:100]\n",
    "words = np.append(words, [t1+t2 for t1,t2 in zip(not_en[:-1], not_en[1:]) if d.check(t1+t2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.en import English\n",
    "tagger = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger(u' '.join(words[isUS|isGB]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.check('Katz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [w for w in tagger(u' '.join(words[isUS|isGB])) if w.pos_ not in {u'X', u'PUNCT'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print [(w.orth_, w.pos_) for w in tagger(u' '.join(words[isUS|isGB][:200]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[w.lemma_ for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub('\\w+[a-z]([A-Z]|\\_\\w)\\w+', '', 'getProperties get_propertiesNow_now but this is ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub('\\w+[a-z]([A-Z]|\\_\\w)*', '', 'getProperties get_PropertiesNow_now but this is ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string.letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
