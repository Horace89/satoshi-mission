{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part of Speech Taggers\n",
    "* since no. of words is small -- want high accuracy, ok to be slower\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "import nltk.data                        # use pre-trained Punkt tokenizer\n",
    "\n",
    "# Testing Part of Speech Taggers\n",
    "maxnet_tagger = nltk.data.load('taggers/maxent_treebank_pos_tagger/english.pickle')  # pre-trained\n",
    "stanford_tagger = StanfordPOSTagger('english-bidirectional-distsim.tagger')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = 'The quick brown fox jumps over the lazy dog'.split()\n",
    "%timeit maxnet_tagger.tag(test)    # 8.04 ms per loop - best\n",
    "maxnet_tagger.tag(test)            # least accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit stanford_tagger.tag(test)   # 2.47 s per loop - slowest\n",
    "stanford_tagger.tag(test)           # most accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testblob = TextBlob('The quick brown fox jumps over the lazy dog')\n",
    "%timeit testblob.tags  # 2.05 s per loop\n",
    "testblob.tags          # mediocre accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.en import English\n",
    "tagger = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit a = tagger(u'The quick brown fox jumps over the lazy dog')\n",
    "a = tagger(u'The quick brown fox jumps over the lazy dog')\n",
    "for token in a:\n",
    "    print token.orth_, token.tag_, token.pos_    # fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tagger(u'is was been has have being jumps jump wrote write')\n",
    "for token in a:\n",
    "    print token.orth_, token.lemma_, token.is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lst = ['hi', 'there']\n",
    "Counter(w.tag_.encode('ascii') for w in tagger(u' '.join(lst)))\n",
    "# for token in a:\n",
    "#     print token.orth_, token.tag_    # fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'a$'.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing US/GB Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "\n",
    "d1 = enchant.Dict('en_US')  # not in dic: spam, spamming, spammers\n",
    "d2 = enchant.Dict('en_GB')  # not in dic: i, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = 'wxgtk'\n",
    "print d1.check(s), d2.check(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='background-color: #fff; border-top: 2px dashed #8c8b8b;'>\n",
    "# Functions\n",
    "(Converted to `../code/dbio.py` and `../code/basic_stats.py`)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division         # no need to worry about integer division\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import psycopg2 as pg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT, AsIs\n",
    "\n",
    "import string, re\n",
    "from collections import Counter\n",
    "from itertools import chain, izip\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "import nltk.data                        # use pre-trained Punkt tokenizer\n",
    "from nltk.corpus import stopwords       # using this set of stopwords for the model\n",
    "import enchant                          # pyenchant -- US vs. GB spelling\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'author': 'varchar(10)',\n",
    "     'date'  : 'timestamptz',\n",
    "     'type'  : 'varchar(10)'}\n",
    "a, b = zip(*sorted(d.iteritems()))\n",
    "print a\n",
    "print b\n",
    "tuple(chain(*zip(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='background-color: #fff; border-top: 2px dashed #8c8b8b;'>\n",
    "# Debug Anomalies:\n",
    "* satoshi:\n",
    "    * forum@236<br>\n",
    "        ```\n",
    "        StandfordPOSTagger error (java.lang.OutOfMemoryError)\n",
    "        ```\n",
    "    * forum@470<br>\n",
    "        ```\n",
    "        ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
    "        ```\n",
    "        \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python basic_stats.py satoshi -wt paper -rt True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python basic_stats.py satoshi -wt email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python basic_stats.py satoshi -wt forum -s 236 -e 237\n",
    "# skipped 236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly \"forum@236\"\n",
    "\n",
    "* len(forum@236) = ~380 words\n",
    "* verified *NOT* a python list vs. numpy array problem\n",
    "* error when processing all words at once \n",
    "* no error when feed word into tagger one by one *AND* in each loop do a try-except catch\n",
    "* error running slicing\n",
    "* error running for loop without try-except catch\n",
    "* `$ java -XX:+PrintFlagsFinal | grep 'MaxHeapSize'`: 1073741824 byte = 1GB\n",
    "* but much longer paper (~3000 words) didn't cause this error... maybe too many words not in English? (e.g. computer variables)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db  = client['satoshi']\n",
    "tbl = db['raw-docs']\n",
    "\n",
    "query_results = tbl.find( {'author': {'$eq': 'satoshi' },\n",
    "                                      'type'  : {'$eq': 'forum' }   } )\n",
    "\n",
    "results = [r for r in query_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# satoshi forum 236 -- problematic for StandfordPOSTagger\n",
    "ctr, words, misspellings, gb_spellings, us_spellings = crunch_statistics(results[236]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_tagger = StanfordPOSTagger('english-bidirectional-distsim.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poses = []\n",
    "for i,word in enumerate(words[:100]):\n",
    "    try:\n",
    "        lst = stanford_tagger.tag(word)\n",
    "        print i,t\n",
    "        lst += lst[0][-1].encode('ascii')\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = stanford_tagger.tag(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly \"forum@470\"\n",
    "\n",
    "* lines are all '\\n', so no words!\n",
    "* check original post -- all computer code so correctly removed everything\n",
    "* numpy boolean selection doesn't like empty selector... \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.array([])\n",
    "~b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='background-color: #fff; border-top: 2px dashed #8c8b8b;'>\n",
    "# Chunking and Boostrapping\n",
    "\n",
    "(Converted to `prep_sents.py`, `chunking.py` and `prep_samples.py`)<br>\n",
    "(code-v2: moved to `helper_function.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr style='background-color: #fff; border-top: 2px dashed #8c8b8b;'>\n",
    "# Get 250 Most Frequent Words\n",
    "\n",
    "(Converted to `../code/term_freq.py`)<br>\n",
    "(code-v2: moved to `helper_function.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
